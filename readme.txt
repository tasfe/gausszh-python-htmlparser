开发环境：eclipse+pydev

html_parser.py 主文件
outputFile.xml 输出存储文件
template.xml 输出格式的要求

实现了循环爬取（通过提取每个app页面中的其他app的URL实现下一个爬取）

性能分析：时间的消耗主要是网络的速度以及I/O操作。
在判断爬取的app有没有重复时，我采用的时dict结构。python的字典结构采用的不是C++中的red-black tree方式，而是用hash，也就是说在数据较大的时候更能体现出python的dict优势（因为python内部也采用很多dict的数据，所以对dict的性能要求比较高），有时能够达到O（1）的速度，这是非常可观的。

大数据方面：文件读写，我为了加快速度，采用的是先将数据写入内存然再存入硬盘。为了避免数据实在太大，内存不够。我的方案是，每抓取10000个app就存一次硬盘(源码275行)。

异常处理：
能够保证某一个app处理错误的时候，不影响下一个app的爬取。


ps:代码这么长，其实主要都花在输出格式的调整那里了。